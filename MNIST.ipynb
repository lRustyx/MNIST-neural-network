{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6ad847bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c58bd117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47318cf7b6014e4abb36dca7462f0184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "268572c8f53f42bc95da4e8477b0c077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b41992d0204d579e0a23fe8a42e9cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5616b88e2732461bad88d396b426d0e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_dataset = torchvision.datasets.MNIST(root = './data', train = True, transform = transforms.ToTensor(), download = True)\n",
    "testing_dataset = torchvision.datasets.MNIST(root = './data', train = False, transform = transforms.ToTensor(), download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0fd5c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "batch_size = 32\n",
    "\n",
    "input_size = 28*28\n",
    "hidden_size1 = 400\n",
    "hidden_size2 = 400\n",
    "output_size = 10\n",
    "\n",
    "\n",
    "epochs = 4\n",
    "learning_rate = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "19ea5750",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(training_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(testing_dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c720db0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 28, 28])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing example to get dimensions\n",
    "ex = iter(train_loader)\n",
    "sample, label = next(ex)\n",
    "sample.size() # 28 by 28 picture with 1 dimension (black and white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e89daad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x227effffb50>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4c21589f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        \n",
    "        super(NeuralNet, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.layer2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.layer3 = nn.Linear(hidden_size2, output_size)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, sample):\n",
    "        \n",
    "        out = self.relu(self.layer1(sample))\n",
    "        out = self.relu(self.layer2(out))\n",
    "        out = self.layer3(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "818007bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size, hidden_size1, hidden_size2, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "19d6feda",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "50e4b2a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/4, step: 100/1875, loss:0.6391429901123047\n",
      "epoch: 1/4, step: 200/1875, loss:0.26829084753990173\n",
      "epoch: 1/4, step: 300/1875, loss:0.2896983325481415\n",
      "epoch: 1/4, step: 400/1875, loss:0.2924205958843231\n",
      "epoch: 1/4, step: 500/1875, loss:0.38004934787750244\n",
      "epoch: 1/4, step: 600/1875, loss:0.43061378598213196\n",
      "epoch: 1/4, step: 700/1875, loss:0.10937750339508057\n",
      "epoch: 1/4, step: 800/1875, loss:0.08167070895433426\n",
      "epoch: 1/4, step: 900/1875, loss:0.5440568327903748\n",
      "epoch: 1/4, step: 1000/1875, loss:0.08424112200737\n",
      "epoch: 1/4, step: 1100/1875, loss:0.02979118563234806\n",
      "epoch: 1/4, step: 1200/1875, loss:0.29626697301864624\n",
      "epoch: 1/4, step: 1300/1875, loss:0.09569810330867767\n",
      "epoch: 1/4, step: 1400/1875, loss:0.12462662160396576\n",
      "epoch: 1/4, step: 1500/1875, loss:0.03755493089556694\n",
      "epoch: 1/4, step: 1600/1875, loss:0.2760908007621765\n",
      "epoch: 1/4, step: 1700/1875, loss:0.011713665910065174\n",
      "epoch: 1/4, step: 1800/1875, loss:0.1307186335325241\n",
      "epoch: 2/4, step: 100/1875, loss:0.17245592176914215\n",
      "epoch: 2/4, step: 200/1875, loss:0.2487412393093109\n",
      "epoch: 2/4, step: 300/1875, loss:0.1337445229291916\n",
      "epoch: 2/4, step: 400/1875, loss:0.17481185495853424\n",
      "epoch: 2/4, step: 500/1875, loss:0.17262805998325348\n",
      "epoch: 2/4, step: 600/1875, loss:0.16394704580307007\n",
      "epoch: 2/4, step: 700/1875, loss:0.018943417817354202\n",
      "epoch: 2/4, step: 800/1875, loss:0.23209156095981598\n",
      "epoch: 2/4, step: 900/1875, loss:0.002464616671204567\n",
      "epoch: 2/4, step: 1000/1875, loss:0.06356322020292282\n",
      "epoch: 2/4, step: 1100/1875, loss:0.002917900215834379\n",
      "epoch: 2/4, step: 1200/1875, loss:0.019889045506715775\n",
      "epoch: 2/4, step: 1300/1875, loss:0.1829972118139267\n",
      "epoch: 2/4, step: 1400/1875, loss:0.010943097062408924\n",
      "epoch: 2/4, step: 1500/1875, loss:0.14949990808963776\n",
      "epoch: 2/4, step: 1600/1875, loss:0.02037941664457321\n",
      "epoch: 2/4, step: 1700/1875, loss:0.07392134517431259\n",
      "epoch: 2/4, step: 1800/1875, loss:0.06018805503845215\n",
      "epoch: 3/4, step: 100/1875, loss:0.022856730967760086\n",
      "epoch: 3/4, step: 200/1875, loss:0.004976584110409021\n",
      "epoch: 3/4, step: 300/1875, loss:0.14031194150447845\n",
      "epoch: 3/4, step: 400/1875, loss:0.010626952163875103\n",
      "epoch: 3/4, step: 500/1875, loss:0.19129683077335358\n",
      "epoch: 3/4, step: 600/1875, loss:0.08024007081985474\n",
      "epoch: 3/4, step: 700/1875, loss:0.008533371612429619\n",
      "epoch: 3/4, step: 800/1875, loss:0.02561303600668907\n",
      "epoch: 3/4, step: 900/1875, loss:0.0004274935054127127\n",
      "epoch: 3/4, step: 1000/1875, loss:0.018336834385991096\n",
      "epoch: 3/4, step: 1100/1875, loss:0.004793011583387852\n",
      "epoch: 3/4, step: 1200/1875, loss:0.004537730943411589\n",
      "epoch: 3/4, step: 1300/1875, loss:0.011701132170855999\n",
      "epoch: 3/4, step: 1400/1875, loss:0.02670244686305523\n",
      "epoch: 3/4, step: 1500/1875, loss:0.018606308847665787\n",
      "epoch: 3/4, step: 1600/1875, loss:0.001327300677075982\n",
      "epoch: 3/4, step: 1700/1875, loss:0.03524225950241089\n",
      "epoch: 3/4, step: 1800/1875, loss:0.09287599474191666\n",
      "epoch: 4/4, step: 100/1875, loss:0.010981638915836811\n",
      "epoch: 4/4, step: 200/1875, loss:0.022088680416345596\n",
      "epoch: 4/4, step: 300/1875, loss:0.00681261345744133\n",
      "epoch: 4/4, step: 400/1875, loss:0.0014397625345736742\n",
      "epoch: 4/4, step: 500/1875, loss:0.024976780638098717\n",
      "epoch: 4/4, step: 600/1875, loss:0.036445774137973785\n",
      "epoch: 4/4, step: 700/1875, loss:0.037592317909002304\n",
      "epoch: 4/4, step: 800/1875, loss:0.00552009791135788\n",
      "epoch: 4/4, step: 900/1875, loss:0.280597448348999\n",
      "epoch: 4/4, step: 1000/1875, loss:0.06390029191970825\n",
      "epoch: 4/4, step: 1100/1875, loss:0.13421843945980072\n",
      "epoch: 4/4, step: 1200/1875, loss:0.09679590910673141\n",
      "epoch: 4/4, step: 1300/1875, loss:0.17638933658599854\n",
      "epoch: 4/4, step: 1400/1875, loss:0.0014291104162111878\n",
      "epoch: 4/4, step: 1500/1875, loss:0.018363097682595253\n",
      "epoch: 4/4, step: 1600/1875, loss:0.018373601138591766\n",
      "epoch: 4/4, step: 1700/1875, loss:0.009408196434378624\n",
      "epoch: 4/4, step: 1800/1875, loss:0.021039312705397606\n",
      "Time taken: 171.74232387542725 seconds\n"
     ]
    }
   ],
   "source": [
    "steps = len(train_loader)\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    for i, (image, label) in enumerate(train_loader):\n",
    "        image = image.reshape(-1,28*28)\n",
    "        \n",
    "        output = model(image)\n",
    "        loss = loss_function(output,label)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1)%100 == 0:\n",
    "            print(f'epoch: {epoch+1}/{epochs}, step: {i+1}/{steps}, loss:{loss}')\n",
    "        \n",
    "        \n",
    "print(f'Time taken: {time.time()-start_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "12a3a921",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    prediction_list = torch.tensor([])\n",
    "    label_list = torch.tensor([])\n",
    "    \n",
    "    for image, label in test_loader:\n",
    "        image = image.reshape(-1,28*28)\n",
    "        output = model(image)\n",
    "        value, prediction = torch.max(output,1)\n",
    "        \n",
    "        prediction_list = torch.cat((prediction_list,prediction),0)\n",
    "        label_list = torch.cat((label_list,label),0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b5e04a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 941,    0,    0,    1,    0,    0,    4,    3,    3,   28],\n",
       "       [   0, 1125,    0,    0,    0,    1,    2,    0,    7,    0],\n",
       "       [   1,    3, 1007,   11,    3,    0,    0,    3,    4,    0],\n",
       "       [   0,    0,    4,  997,    0,    2,    0,    2,    2,    3],\n",
       "       [   0,    1,    3,    0,  965,    0,    4,    0,    4,    5],\n",
       "       [   3,    1,    0,   20,    1,  857,    5,    0,    3,    2],\n",
       "       [   2,    2,    0,    1,    2,    4,  943,    0,    4,    0],\n",
       "       [   1,    7,   10,    5,    1,    0,    0,  999,    2,    3],\n",
       "       [   0,    1,    3,   12,    1,    5,    0,    2,  943,    7],\n",
       "       [   0,    4,    0,    7,   13,    0,    1,    6,    1,  977]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(label_list,prediction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e3e9dae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.54"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (prediction_list == label_list).sum().item() / len(label_list) * 100\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746377a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
